{
 "metadata": {
  "name": "",
  "signature": "sha256:9082ad1edaed820a687b86464be60da62c0d2f20225e81a711ef3a2a3c3efe2c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "text = nltk.word_tokenize(\"And now for something compleyely difference\")\n",
      "print(text)\n",
      "print(nltk.pos_tag(text))\n",
      "print(nltk.corpus.brown.tagged_words())\n",
      "text = \"The/AT grand/JJ is/VBD .\"\n",
      "print([nltk.str2tuple(i) for i in text.split()])\n",
      "from nltk.corpus import brown\n",
      "word_tag = nltk.FreqDist(brown.tagged_words(categories=\"news\"))\n",
      "#print [word+\"/\"+tag for (word,tag) in word_tag if tag.startswith('V')]\n",
      "type(word_tag)\n",
      "wsj = brown.tagged_words(categories=\"news\")\n",
      "cfd = nltk.ConditionalFreqDist(wsj)\n",
      "print cfd['money'].keys()\n",
      "def findtag(tag_prefix,tagged_text):\n",
      "    cfd = nltk.ConditionalFreqDist((tag,word) for (word,tag) in tagged_text if tag.startswith(tag_prefix))\n",
      "    return dict((tag,list(cfd[tag].keys())[:5]) for tag in cfd.conditions())\n",
      "tagdict = findtag('NN',nltk.corpus.brown.tagged_words(categories=\"news\"))\n",
      "for tag in sorted(tagdict):\n",
      "    print(tag,tagdict[tag])\n",
      "\n",
      "brown_tagged = brown.tagged_words(categories=\"news\")\n",
      "tags = [b[1] for (a,b) in nltk.bigrams(brown_tagged) if a[0] ==\"often\"]\n",
      "fd = nltk.FreqDist(tags)\n",
      "fd.tabulate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u6587\u672c\u5206\u7c7b\u793a\u4f8b\n",
      "import random\n",
      "import nltk\n",
      "from nltk.corpus import movie_reviews\n",
      "docs = [(list(movie_reviews.words(fileid)),category) \n",
      "        for category in movie_reviews.categories() \n",
      "        for fileid in movie_reviews.fileids(category)]\n",
      "random.shuffle(docs)\n",
      "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
      "most_common_word = [word for (word,_) in all_words.most_common(2000)]\n",
      "def doc_features(doc):\n",
      "    doc_words = set(doc)\n",
      "    feature = {}\n",
      "    for word in most_common_word:\n",
      "        feature[word] = (word in doc_words)\n",
      "    return feature\n",
      "train_set = nltk.apply_features(doc_features,docs[:100])\n",
      "test_set = nltk.apply_features(doc_features,docs[100:])\n",
      "classfier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "print nltk.classify.accuracy(classfier,test_set)\n",
      "classfier.show_most_informative_features()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u8bcd\u6027\u6807\u6ce8\u5668\n",
      "import nltk\n",
      "from nltk.corpus import brown\n",
      "def pos_feature_use_hist(sentence,i,history):\n",
      "    features={\"suffix-1\": sentence[i][-1:],\n",
      "              \"suffix-2\": sentence[i][-2:],\n",
      "              \"suffix-3\": sentence[i][-3:],\n",
      "              \"pre-word\": 'START',\n",
      "              \"prev-word\": 'START'}\n",
      "    if i >0:\n",
      "        features['pre-word'] = sentence[i-1]\n",
      "        features['prev-word'] = history[i-1]\n",
      "    return features\n",
      "class ContextPosTagger(nltk.TaggerI):\n",
      "    def __init__(self,train):\n",
      "        train_set = []\n",
      "        for tagged_sent in train:\n",
      "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
      "            history=[]\n",
      "            for i,(word,tag) in enumerate(tagged_sent):\n",
      "                features = pos_feature_use_hist(untagged_sent,i,history)\n",
      "                train_set.append((features,tag))\n",
      "                history.append(tag)\n",
      "        #print train_set[:10]\n",
      "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "    def tag(self,sent):\n",
      "        history = []\n",
      "        for i,word in enumerate(sent):\n",
      "            features = pos_feature_use_hist(sent,i,history)\n",
      "            tag = self.classifier.classify(features)\n",
      "            history.append(tag)\n",
      "        return zip(sent,history)\n",
      "tagged_sents = brown.tagged_sents(categories=\"news\")\n",
      "size = int(len(tagged_sents)*0.8)\n",
      "train_sents,test_sents= tagged_sents[:size],tagged_sents[size:]\n",
      "tagger = ContextPosTagger(train_sents)\n",
      "tagger.classifier.show_most_informative_features()\n",
      "#len(test_sents)\n",
      "print tagger.evaluate(test_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "                suffix-1 = u'.'                . : NN     =   6459.2 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                suffix-2 = u'he'              AT : NN     =   2991.3 : 1.0\n",
        "               prev-word = u'TO'              VB : NN     =   2891.2 : 1.0\n",
        "                suffix-2 = u'ho'             WPS : NN     =   2596.0 : 1.0\n",
        "               prev-word = u'MD'              BE : AT     =   2582.0 : 1.0\n",
        "               prev-word = u'HVZ'            BEN : NN     =   2005.9 : 1.0\n",
        "                suffix-2 = u'to'              TO : JJ     =   1822.0 : 1.0\n",
        "                suffix-2 = u'be'              BE : NP     =   1504.3 : 1.0\n",
        "                suffix-3 = u'hat'             CS : NN     =   1466.9 : 1.0\n",
        "                suffix-2 = u'es'             NNS : IN     =   1403.8 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagger.tag(nltk.word_tokenize('this is a tnt treebank tnt tagger'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[('this', u'DT'),\n",
        " ('is', u'BEZ'),\n",
        " ('a', u'AT'),\n",
        " ('tnt', u'NN'),\n",
        " ('treebank', u'NN'),\n",
        " ('tnt', u'NN'),\n",
        " ('tagger', u'NN')]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}