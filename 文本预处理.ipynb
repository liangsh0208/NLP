{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stopworddic = set(stopwords.words('english'))\n",
    "print(stopworddic)\n",
    "text = 'I was just a kid, and loved it very much! What a fantastic song!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Natural language processing (NLP) Is A SuBfield Of Computer scIence, inFormation eNgineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data!?!!....'\n",
    "lower = text.lower()\n",
    "import string\n",
    "remove = str.maketrans('','',string.punctuation)\n",
    "without_punctuation = lower.translate(remove)\n",
    "#分词\n",
    "import nltk\n",
    "tokens = nltk.word_tokenize(without_punctuation)\n",
    "#去停用词\n",
    "from nltk.corpus import  stopwords\n",
    "without_stopwords = [w for w in tokens if not w in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#词干提取\n",
    "import nltk.stem\n",
    "s = nltk.stem.SnowballStemmer('english')\n",
    "cleaned_text = [s.stem(ws) for ws in without_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'nlp', 'subfield', 'comput', 'scienc', 'inform', 'engin', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', 'natur', 'languag', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data']\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chinese = '自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。自然语言处理是一门融语言学、计算机科学、数学于一体的科学。因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，所以它与语言学的研究有着密切的联系，但又有重要的区别。自然语言处理并不是一般地研究自然语言，而在于研制能有效地实现自然语言通信的计算机系统，特别是其中的软件系统。因而它是计算机科学的一部分。'\n",
    "\n",
    "import re\n",
    "from zhon.hanzi import  punctuation\n",
    "import jieba\n",
    "\n",
    "chi_nopuc = re.sub(\"[{}]+\".format(punctuation),\"\", text_chinese)\n",
    "\n",
    "chi_token = jieba.lcut(chi_nopuc)\n",
    "\n",
    "f = open(\"chi_stopwords.txt\",'r',encoding=\"UTF-8\")\n",
    "stopwords_n = f.readlines()\n",
    "f.close()\n",
    "stopwords = [sw.strip().replace('\\n','') for sw in stopwords_n]\n",
    "\n",
    "final = []\n",
    "for chi in chi_token:\n",
    "    if chi not in stopwords:\n",
    "        final.append(chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['自然语言', '计算机科学', '领域', '人工智能', '领域', '方向', '研究', '计算机', '自然语言', '通信', '理论', '方法', '自然语言', '一门', '融', '语言学', '计算机科学', '数学', '一体', '科学', '领域', '研究', '涉及', '自然语言', '日常', '语言', '语言学', '研究', '区别', '自然语言', '研究', '自然语言', '研制', '自然语言', '通信', '计算机系统', '特别', '软件系统', '计算机科学', '一部分']\n"
     ]
    }
   ],
   "source": [
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
